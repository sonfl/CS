<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
       &middot; Computer Science and Math notes
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/CS/public/css/poole.css">
  <link rel="stylesheet" href="/CS/public/css/syntax.css">
  <link rel="stylesheet" href="/CS/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/CS/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/CS/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>

  
<script>
function cvonk_ResizeMathJax() {
    jQuery('.MathJax_Display').each(function(ii, obj) {
        var latex = obj.children[0];
        var w = latex.offsetWidth;
        var h = latex.offsetHeight;    
        var W = obj.offsetWidth;
        if (w > W) {
            obj.style.fontSize = 85 * W / w + "%";
        }
    });
}
window.MathJax = {
    AuthorInit: function() {
    MathJax.Hub.Register.StartupHook("Begin", function() {
        MathJax.Hub.Queue(function() {
        cvonk_ResizeMathJax();
        });
    });
    },
    jax: ["input/TeX", "output/HTML-CSS", "output/NativeMML"],
    extensions: ["tex2jax.js"]
};
window.addEventListener("resize", function() {
    cvonk_ResizeMathJax();  
});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    },
    "HTML-CSS": {
        styles: {".MathJax": {
          color: "#033 ! important"}
                  }
    },
    SVG: { 
      linebreaks: { automatic: true } 
    }
  });
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
>
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://vincenttam.github.io/javascripts/MathJaxLocal.js"
>

</script>


  <body class="theme-base-0f layout-reverse">

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>Notes on CS made by an independent learner. Want to discuss something? Here we go: <a href="https://t.me/slonecznik">Telegram</a>, <a href="https://github.com/sonfl">Github</a></p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/CS/">Home</a>

    

    
    
      
        
      
    
      
        
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="/CS/machine-learning/">Andrew Ng's Machine Learning</a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    <!--
    <a class="sidebar-nav-item" href="/archive/v.zip">Download</a>
    <a class="sidebar-nav-item" href="">GitHub project</a>
  </nav>
   -->

</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/CS/" title="Home">Computer Science and Math notes</a>
            <small>powered by coffee and whiteboard</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <p>Generative Learning is an approach to decide whether $x$ is in set 1 or set 2 of data. We do it by means of making the model to predict set 1 and another model to predict set 2. And assign $x$ to the set, where the probability is greater.</p>

<p>Therefore discriminative are of form: $p(y \vert x)$</p>

<p>Generative: $p(x \vert y)$ and $p(y)$</p>

<p>After we model our models(above), we can use Bayes rule to get:</p>

<script type="math/tex; mode=display">p(y \vert x) = \frac{p(x \vert y)p(y)}{p(x)}</script>

<p>where $p(x) = p(x \vert y=1)p(y=1)+p(x \vert y=0)p(y=0)$</p>

<p>The first example of such a learning is</p>

<blockquote>
  <p>Gaussian discriminant analysis(GDA)</p>
</blockquote>

<p>In this model we assume that $p(x \vert y) is distributed according to multivariate normal distribution, which is:</p>

<p><script type="math/tex">p(x;\mu,\Sigma) = \frac{1}{(2\pi)^{n/2}\vert \Sigma \vert ^{\frac{1}{2}}}e^{-\frac{1}{2}(x-\mu)^{T}\Sigma^{-1}(x-\mu)}</script>,</p>

<p>where $\Sigma$ is a covariance matrix</p>

<p>Letâ€™s have an example of GDA:</p>

<p>Our model will be as such:</p>

<p>$ y \sim$ Bernoulli($\phi$)</p>

<p>$x \vert y=0 \sim \mathcal{N}(\mu_{0}, \Sigma)$</p>

<p>$x \vert y=1 \sim \mathcal{N}(\mu_{1}, \Sigma)$</p>

<p>Therefore we have:</p>

<p>$p(y) = \phi^{y}(1-\phi)^{1-y}$</p>

<p>$p(x \vert y=0) = \frac{1}{(2\pi)^{n/2}\vert \Sigma \vert ^{\frac{1}{2}}}e^{-\frac{1}{2}(x-\mu_{0})^{T}\Sigma^{-1}(x-\mu_{0})}$</p>

<p>$p(x \vert y=1) = \frac{1}{(2\pi)^{n/2}\vert \Sigma \vert ^{\frac{1}{2}}}e^{-\frac{1}{2}(x-\mu_{1})^{T}\Sigma^{-1}(x-\mu_{1})}$</p>

<p>And now our dear log likelihood:</p>

<p>$l(\phi, \mu_{0}, \mu_{1}, \Sigma) = log \prod_{i=1}^{m}p(x^{(i)}, y^{(i)}) = log \prod_{i=1}^{m}p(x^{(i)} \vert y^{(i)})p(y^{(i)})$</p>

<p>To predict we need $argmax_{y}P(y \vert x) = argmax_{y}P(x \vert y)P(y)$</p>

<p>Also by some magic steps we can observe that somehow $p(y=1 \vert x; \Sigma, \mu_{0}, \mu_{1}) = \frac{1}{1+e^{-\theta^{T}x}}$, which we used to model $p(y=1 \vert x)$</p>

<p>So when we would prefer GDA over logistic regression and vica versa?</p>

<p>Apparently, if we have multivariate gaussian we get logistical regression, but the converse is not true. So we may think of GDA as a stronger modelling. Therefore it is more efficient. But on the other hand, if we make incorrect assumptions, we would be better off with weaker logistic regression, which would handle all inconsistencies with the data.</p>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
